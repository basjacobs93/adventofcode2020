{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath, fun = lambda x: x):\n",
    "    \"\"\"\n",
    "    Read file at location `filepath`, apply `fun` to every line,\n",
    "    and return the result as a list.\n",
    "    \"\"\"\n",
    "    with open(filepath) as f:\n",
    "        return [fun(i.strip()) for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1: Report Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = read_file(\"input/1.txt\", int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comb in combinations(numbers, 2):\n",
    "    if sum(comb) == 2020:\n",
    "        print(comb, reduce(mul, comb))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comb in combinations(numbers, 3):\n",
    "    if sum(comb) == 2020:\n",
    "        print(comb, reduce(mul, comb))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: Password Philosophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"(\\d+)-(\\d+) (\\w): (\\w+)\")\n",
    "\n",
    "def cleaner_day2(line):\n",
    "    mini, maxi, char, password = pattern.findall(line)[0]\n",
    "    return int(mini), int(maxi), char, password\n",
    "\n",
    "policies = read_file(\"input/2.txt\", cleaner_day2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for mini, maxi, char, password in policies:\n",
    "    if mini <= password.count(char) <= maxi:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, j, char, password in policies:\n",
    "    if sum([password[i-1] == char, password[j-1] == char]) == 1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3: Toboggan Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treemap = read_file(\"input/3.txt\")\n",
    "nrows = len(treemap)\n",
    "ncols = len(treemap[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = col = 0\n",
    "tree_count = 0\n",
    "slope_col, slope_row = (3, 1)\n",
    "\n",
    "while row < nrows-slope_row:\n",
    "    row = row + slope_row\n",
    "    col = (col + slope_col) % ncols\n",
    "    tree_count += treemap[row][col] == \"#\"\n",
    "    \n",
    "tree_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes = [(1, 1), (3, 1), (5, 1), (7, 1), (1, 2)]\n",
    "prod = 1\n",
    "\n",
    "for slope_col, slope_row in slopes:\n",
    "    row = col = 0\n",
    "    tree_count = 0\n",
    "\n",
    "    while row < nrows-slope_row:\n",
    "        row = row + slope_row\n",
    "        col = (col + slope_col) % ncols\n",
    "        tree_count += treemap[row][col] == \"#\"\n",
    "\n",
    "    prod *= tree_count\n",
    "prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4: Passport Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = read_file(\"input/4.txt\")\n",
    "\n",
    "passports = []\n",
    "passport_buildup = []\n",
    "\n",
    "for line in lines:\n",
    "    if line == \"\":\n",
    "        passport = dict(pb.split(\":\") for pb in passport_buildup)\n",
    "        passports.append(passport)\n",
    "        passport_buildup = []\n",
    "    else:\n",
    "        passport_buildup += line.split(\" \")\n",
    "\n",
    "# Add last line as well\n",
    "passport = dict(pb.split(\":\") for pb in passport_buildup)\n",
    "passports.append(passport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_fields = {\"byr\", \"iyr\", \"eyr\", \"hgt\", \"hcl\", \"ecl\", \"pid\"}\n",
    "\n",
    "len([passport for passport in passports if needed_fields.issubset(passport.keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(passport):\n",
    "    \"\"\"\n",
    "    Checks for the following fields\n",
    "    \n",
    "    byr (Birth Year) - four digits; at least 1920 and at most 2002.\n",
    "    iyr (Issue Year) - four digits; at least 2010 and at most 2020.\n",
    "    eyr (Expiration Year) - four digits; at least 2020 and at most 2030.\n",
    "    hgt (Height) - a number followed by either cm or in:\n",
    "    If cm, the number must be at least 150 and at most 193.\n",
    "    If in, the number must be at least 59 and at most 76.\n",
    "    hcl (Hair Color) - a # followed by exactly six characters 0-9 or a-f.\n",
    "    ecl (Eye Color) - exactly one of: amb blu brn gry grn hzl oth.\n",
    "    pid (Passport ID) - a nine-digit number, including leading zeroes.\n",
    "    cid (Country ID) - ignored, missing or not.\n",
    "    \"\"\"\n",
    "    if not needed_fields.issubset(passport.keys()):\n",
    "        return False\n",
    "        \n",
    "    # byr\n",
    "    if not (re.match(\"\\d{4}$\", passport[\"byr\"]) and 1920 <= int(passport[\"byr\"]) <= 2002):\n",
    "        return False\n",
    "    \n",
    "    # iyr\n",
    "    if not (re.match(\"\\d{4}$\", passport[\"iyr\"]) and 2010 <= int(passport[\"iyr\"]) <= 2020):\n",
    "        return False\n",
    "\n",
    "    # eyr\n",
    "    if not (re.match(\"\\d{4}$\", passport[\"eyr\"]) and 2020 <= int(passport[\"eyr\"]) <= 2030):\n",
    "        return False\n",
    "    \n",
    "    # hgt\n",
    "    hgt = re.match(\"(\\d+)(cm|in)$\", passport[\"hgt\"])\n",
    "    if not hgt:\n",
    "        return False\n",
    "    if hgt.group(2) == \"cm\":\n",
    "        if not (150 <= int(hgt.group(1)) <= 193):\n",
    "            return False\n",
    "    else:\n",
    "        if not (59 <= int(hgt.group(1)) <= 76):\n",
    "            return False\n",
    "    \n",
    "    # hcl\n",
    "    if not re.match(\"#[0-9a-f]{6}$\", passport[\"hcl\"]):\n",
    "        return False\n",
    "            \n",
    "    # ecl\n",
    "    if not passport[\"ecl\"] in \"amb blu brn gry grn hzl oth\".split(\" \"):\n",
    "        return False\n",
    "    \n",
    "    # pid\n",
    "    if not re.match(\"\\d{9}$\", passport[\"pid\"]):\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len([passport for passport in passports if is_valid(passport)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5: Binary Boarding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans({\"F\": \"0\", \"B\": \"1\",\n",
    "                            \"R\": \"1\", \"L\": \"0\"})\n",
    "\n",
    "def seat_to_number(seat):\n",
    "    \"\"\"\n",
    "    Turn seat string into a seat number by turning \n",
    "    it into a binary number and parsing it\n",
    "    \"\"\"\n",
    "    seat = seat.translate(translator)\n",
    "    row, col = seat[:7], seat[7:]\n",
    "    row, col = int(row, 2), int(col, 2)\n",
    "\n",
    "    return row * 8 + col\n",
    "\n",
    "seat_numbers = read_file(\"input/5.txt\", seat_to_number)\n",
    "seat_numbers = set(seat_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(seat_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seats = set(range(min(seat_numbers), max(seat_numbers)+1))\n",
    "all_seats - seat_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6 - Custom Customs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = read_file(\"input/6.txt\")\n",
    "\n",
    "group = []\n",
    "groups = []\n",
    "\n",
    "for line in lines:\n",
    "    if line == \"\":\n",
    "        groups.append(group)\n",
    "        group = []\n",
    "    else:\n",
    "        group.append(set(pb for pb in line))\n",
    "\n",
    "# Add last group as well\n",
    "groups.append(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [reduce(set.union, group) for group in groups]\n",
    "\n",
    "sum(len(group) for group in combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [reduce(set.intersection, group) for group in groups]\n",
    "\n",
    "sum(len(group) for group in combined)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
